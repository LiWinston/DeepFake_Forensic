# Forensic Tool for Detecting Deepfake and Synthetic Media

## Project Objective
To develop a forensic tool for detecting and analysing deepfake, digitally altered, and synthetic media (AI generated). The system will utilise image and video analysis algorithms, machine learning, and metadata analysis techniques to provide reliable, comprehensive, and automated forensic assistance for forensic investigators.

## Key Requirements
- Detection and analysis of deepfake, digitally altered and synthetic images and video  
- Detailed forensic analysis and reporting of anomalies in images and video sequences  
- User-friendly, intuitive interface for use by forensic investigators and analysts.  

## Media Analysis Algorithms & Techniques (Examples)

### Deep Learning Algorithms
1. **Convolutional Neural Networks (CNNs)**  
   - Extract visual features from frames and detect anomalies or inconsistencies  

2. **Generative Adversarial Networks (GAN) Detection**  
   - Identify media generated by GANs based on feature-level and residual artifacts  

3. **Autoencoders**  
   - Use reconstruction error to identify image/video regions inconsistent with learned normal patterns  

4. **3D CNNs / LRCNs**  
   - Analyse spatial-temporal inconsistencies in video (e.g. unnatural facial expressions or motion)  

5. **Transformers for Video**  
   - Capture long-term temporal dependencies and scene coherence across video frames.  

### Traditional Forensic Techniques
1. **Error Level Analysis (ELA)**  
   - Detect anomalies and inconsistencies in images and video  

2. **Noise Analysis**  
   - Analyse spatial noise distributions for irregularities.  

3. **Local Binary Patterns (LBP)**  
   - Extract texture features to highlight altered regions.  

4. **Copy-Move Forgery Detection**  
   - Identify duplicated regions in images or video frames.  

5. **Temporal Inconsistency Detection**  
   - Identify irregular blinking, facial jitter, or head pose changes in video.  

## Metadata Analysis Techniques
1. **Exif Data Analysis**  
   - Examine metadata from still images and videos for inconsistencies (e.g. device, GPS, timestamps, etc)  

2. **Container Metadata & Frame Hashing**  
   - Use tools to extract and verify structural integrity of video files e.g. FFmpeg.  

3. **Data Header Analysis**  
   - Examine the integrity and consistency of header information to detect tampering.  

4. **Hashing Techniques (MD5, SHA)**  
   - Verify file integrity and identify tampering.  

## Key Functionality
- **Media Upload and Input Handling**  
  - Support for JPEG, PNG, GIF, MP4, AVI etc  
  - Interface for image and video upload  

- **Preprocessing**  
  - Frame extraction (for video), resizing, normalisation, format validation  

- **Detection Modules**  
  - Integrate pre-trained CNN, GAN, and temporal models  
  - Confidence scoring and anomaly flagging  

- **Forensic Analysis Tools**  
  - Implement ELA, noise inconsistency, and LBP-based analysis  
  - Frame-by-frame forgery detection  

- **Metadata Inspection**  
  - Integrate ExifTool, FFmpeg, and hashing libraries.  
  - Display suspicious or altered metadata.  

- **Visualization and Reporting**  
  - Generate heatmaps, ELA overlays, and anomaly scores.  
  - Export findings as PDF/JSON reports.  

- **User Interface**  
  - Simple web UI built with Flask or React.js.  
  - View uploaded media, navigate frames, view analysis.  

- **Storage/Logging**  
  - Save metadata, logs, and forensic results using SQLite or PostgreSQL.  

## Intended Outcomes & Benefits
- A robust, forensically sound tool for investigating deepfake and synthetic media  
- Automated forensic support for visual content verification and analysis  
- Enhanced evidence integrity and chain-of-custody traceability.  
- Modular design to support future integration of audio analysis, multimodal AI created material  

---

# Requirement Change Log

## Week 4 Discussion Summary

### User & Stakeholder Profiles (Who/Do/Be/Feel)

| Who | Do | Be | Feel |
|---|---|---|---|
| **Students** | Model to separate AI images from real images | Software Application (Java/Python application) | Easy to use |
| **Lecturers** | Model to separate AI videos from real videos | Consistent (identify similar/same) reasons for same videos | - |
| **University of Melbourne** | Providing forensic insight (reason) for the separation | Reliable and accurately identifying the real and deepfake videos | - |
| **Tutors** | Take feedback from client based on varying success | Provide support for the student and the client | - |
| **Forensic Analyst (client)** | - | - | - |
| **Government** | - | - | - |

### Key Client Requirements & Insights

- **Core Task:** The client wants to know if a video/image is real, edited, or AI-generated
- **Interpretability:** Interpretability is crucial for forensic analysts
    - For images, use heatmaps to show exactly which parts are AI-generated
    - For videos, identify which specific frames are AI-generated
- **Reporting:** A potential solution is to use a large language model (like ChatGPT API) to generate a formal forensic report based on algorithmic and metadata analysis results. This would make the client's life easier and produce a report suitable for court
- **Edited Media:** Training data exists for real vs. AI-generated media, but how to tell if something is merely edited?
    - **Proposed Solution:** Use algorithmic approaches to detect edited content

### System Architecture & Implementation Notes

- **Models:** Potentially implement an image detection CNN and apply it to video frame-by-frame analysis
- **Model Training:** It's preferable to use pre-trained models and fine-tune them for performance rather than building new models from scratch
- **Backend Infrastructure:**
    - An ideal scenario includes a user login system
    - Users can create projects and submit multiple images/videos
    - Projects will be stored in the backend until the user deletes them
    - Different users should only have access to their own projects and not be able to cross-access others' data
    - Users should be able to view all their project history, reports, and documents
- **Project Limitations:** No limits to the number or type of projects, only limited by technological constraints, such as not being able to process a 10-hour video

### Ethical Considerations

- **Data Usage:** Do not use inappropriate data for training, such as pornographic material, anything involving children, or violence

### Future Research & Exploration

- **Multimodal Analysis:** Explore building a multimodal transformer that can take inputs like audio, images, and metadata to analyze if content is edited, AI-generated, or real
- **Video Transformer:** Research the use of a video transformer for analysis